{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "truedata = np.load(\"3RETransits300ppm_Large.npy\", allow_pickle = True)\n",
    "falsedataA = np.load(\"falsepositive300a.npy\", allow_pickle = True)\n",
    "falsedataB = np.load(\"falsepositive300b.npy\", allow_pickle = True)\n",
    "falsedata = np.append(falsedataA, falsedataB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 1200, 1)\n",
      "(4999,)\n"
     ]
    }
   ],
   "source": [
    "# make categories list\n",
    "y_false = np.full(len(falsedata),0,dtype = int)\n",
    "y_true = np.full(len(truedata),1,dtype = int)\n",
    "\n",
    "y = np.append(y_false,y_true)\n",
    "\n",
    "folded_flux = falsedata[0].folded_y\n",
    "false_phasefolds = np.zeros((len(falsedata),len(folded_flux),1))\n",
    "folded_flux = truedata[0].folded_y\n",
    "true_phasefolds = np.zeros((len(truedata),len(folded_flux),1))\n",
    "\n",
    "for i, data in enumerate(falsedata):\n",
    "    folded_flux = data.folded_y\n",
    "    for j, point in enumerate(folded_flux):\n",
    "        false_phasefolds[i,j] = folded_flux[j]\n",
    "\n",
    "for i, data in enumerate(truedata):\n",
    "    folded_flux = data.folded_y\n",
    "    for j, point in enumerate(folded_flux):\n",
    "        true_phasefolds[i,j] = folded_flux[j]\n",
    "\n",
    "x = np.concatenate((false_phasefolds, true_phasefolds))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = shuffle(x)\n",
    "Y = shuffle(y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 1200, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 1196, 16)          96        \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1192, 16)          1296      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 594, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 590, 32)           2592      \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 586, 32)           5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 291, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 287, 64)           10304     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 283, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 140, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 136, 128)          41088     \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 132, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 60, 256)           164096    \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 56, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 26, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6656)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               3408384   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,589,361\n",
      "Trainable params: 4,589,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# CNN found on https://github.com/pearsonkyle/Exoplanet-Artificial-Intelligence/blob/master/shallue_vanderburg_recreation.py\n",
    "\n",
    "input_global = Input(shape=x_train.shape[1:])\n",
    "x = Conv1D(16, 5, strides=1)(input_global)\n",
    "x = Conv1D(16, 5, strides=1)(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2)(x)\n",
    "x = Conv1D(32, 5, strides=1)(x)\n",
    "x = Conv1D(32, 5, strides=1)(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2)(x)\n",
    "x = Conv1D(64, 5, strides=1)(x)\n",
    "x = Conv1D(64, 5, strides=1)(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2)(x)\n",
    "x = Conv1D(128, 5, strides=1)(x)\n",
    "x = Conv1D(128, 5, strides=1)(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2)(x)\n",
    "x = Conv1D(256, 5, strides=1)(x)\n",
    "x = Conv1D(256, 5, strides=1)(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2)(x)\n",
    "\n",
    "xf = Flatten()(x)\n",
    "z = Dense(512, activation='relu')(xf)\n",
    "z = Dense(512, activation='relu')(z)\n",
    "z = Dense(512, activation='relu')(z)\n",
    "\n",
    "output = Dense(1, activation='sigmoid', name='main_output')(z)\n",
    "\n",
    "model = Model(inputs=input_global, outputs=output)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = [Accuracy(name='acc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 13s 231ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 13s 243ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 13s 230ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 13s 233ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 12s 215ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 12s 216ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 12s 213ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 12s 212ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 11s 209ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 12s 212ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 12s 216ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 12s 224ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 13s 228ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 13s 231ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 12s 213ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 12s 213ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 12s 218ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 12s 212ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 12s 210ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 12s 213ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 12s 216ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 12s 214ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 12s 212ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 12s 212ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 12s 211ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 12s 212ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 13s 239ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 13s 242ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - 13s 235ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 12s 221ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 12s 222ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 12s 225ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 12s 226ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 12s 226ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 12s 226ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 12s 225ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 12s 227ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 2.3678e-08 - acc: 0.0000e+00 - val_loss: 2.4239e-08 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "hist = model.fit(x_train, y_train, epochs=50, batch_size=batch_size, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot model accuracy\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
